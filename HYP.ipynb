{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d623dc-b8af-450a-912b-5204c3c37613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import scipy\n",
    "\n",
    "\n",
    "class Preprocessor(ABC):\n",
    "    @abstractmethod\n",
    "    def process(self, data):\n",
    "        pass\n",
    "\n",
    "class WaveletDenoiserWithThresholdPerLevel(Preprocessor):\n",
    "    def __init__(self, wavelet='db4', level=4, threshold_type='soft'):\n",
    "        self.wavelet = wavelet\n",
    "        self.level = level\n",
    "        if threshold_type not in ['soft', 'hard']:\n",
    "            raise ValueError(\"Invalid threshold type. Select either 'soft' or 'hard'.\")\n",
    "        self.threshold_type = threshold_type\n",
    "\n",
    "    def threshold_func(self, x, threshold, mode):\n",
    "        if mode == 'soft':\n",
    "            return np.sign(x) * np.maximum(np.abs(x) - threshold, 0)\n",
    "        elif mode == 'hard':\n",
    "            return x * (np.abs(x) > threshold)\n",
    "\n",
    "    def process(self, ecg_signal):\n",
    "        # Decompose the signal using DWT\n",
    "        coeffs = pywt.wavedec(ecg_signal, self.wavelet, level=self.level)\n",
    "\n",
    "        # Denoise the wavelet coefficients\n",
    "        denoised_coeffs = []\n",
    "        for i in range(len(coeffs)):\n",
    "            if i == 0:  # do not denoise approximation coeffs at coarsest level\n",
    "                denoised_coeffs.append(coeffs[i])\n",
    "            else:\n",
    "                # Determine the threshold for denoising\n",
    "                sigma = np.median(np.abs(coeffs[i] - np.median(coeffs[i]))) / 0.6745\n",
    "                threshold = sigma * np.sqrt(2 * np.log(len(ecg_signal)))\n",
    "                denoised_coeffs.append(self.threshold_func(coeffs[i], threshold,\n",
    "                                                           self.threshold_type))\n",
    "\n",
    "        # Reconstruct the denoised signal\n",
    "        return pywt.waverec(denoised_coeffs, self.wavelet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dfca34d-3232-4b91-b040-f18e12903c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(df, sampling_rate, path):\n",
    "    x=0\n",
    "    if sampling_rate == 500:\n",
    "        data = []\n",
    "        for f in df.filename_lr:\n",
    "            data.append(wfdb.rdsamp(path+f))\n",
    "    else:\n",
    "        data = []\n",
    "        for f in df.filename_hr:\n",
    "            data.append(wfdb.rdsamp(path+f))\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "path = '/home/oopsie/Documents/PSIML/Projekat/physionet.org/files/ptb-xl/1.0.3/'\n",
    "sampling_rate=100\n",
    "# load and convert annotation data\n",
    "Y = pd.read_csv('/home/oopsie/Documents/PSIML/Projekat/physionet.org/ptbxl_database.csv', index_col='ecg_id')\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed312b5-c3df-4758-a2df-5790641dd8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21799\n",
      "patient_id                 0\n",
      "scp_codes                  0\n",
      "baseline_drift         20201\n",
      "burst_noise            21186\n",
      "electrodes_problems    21769\n",
      "extra_beats            19850\n",
      "pacemaker              21508\n",
      "strat_fold                 0\n",
      "filename_hr                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_name_to_drop1 = ['age','sex','height','weight','nurse','site','device','recording_date','report','heart_axis','infarction_stadium1','infarction_stadium2']\n",
    "column_name_to_drop2= ['validated_by','second_opinion','initial_autogenerated_report','validated_by_human','filename_lr'] \n",
    "Y.drop(column_name_to_drop1, axis=1,inplace=True)\n",
    "Y.drop(column_name_to_drop2, axis=1,inplace=True)\n",
    "Y.drop('static_noise',axis=1,inplace=True)\n",
    "print(len(Y))\n",
    "print(Y.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2e8a59-e6ab-4627-8e88-fd6be9652af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_values = Y.loc[Y['static_noise'].notna() & (Y['baseline_drift'].isna()) & (Y['electrodes_problems'].isna()) & (Y['extra_beats'].isna())& (Y['pacemaker'].isna()), 'patient_id']\n",
    "#values=extracted_values.to_numpy()\n",
    "#print(values)\n",
    "rows_with_nan = Y[Y['baseline_drift'].notna()].index.tolist()\n",
    "Y.drop(rows_with_nan, inplace=True)\n",
    "rows_with_nan = Y[Y['burst_noise'].notna()].index.tolist()\n",
    "Y.drop(rows_with_nan, inplace=True)\n",
    "rows_with_nan = Y[Y['electrodes_problems'].notna()].index.tolist()\n",
    "Y.drop(rows_with_nan, inplace=True)\n",
    "rows_with_nan = Y[Y['extra_beats'].notna()].index.tolist()\n",
    "Y.drop(rows_with_nan, inplace=True)\n",
    "rows_with_nan = Y[Y['pacemaker'].notna()].index.tolist()\n",
    "Y.drop(rows_with_nan, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c3fd09-7e49-49c0-b2ee-8343f07868df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        patient_id                                  scp_codes baseline_drift  \\\n",
      "ecg_id                                                                         \n",
      "1          15709.0   {'NORM': 100.0, 'LVOLT': 0.0, 'SR': 0.0}            NaN   \n",
      "2          13243.0               {'NORM': 80.0, 'SBRAD': 0.0}            NaN   \n",
      "3          20372.0                 {'NORM': 100.0, 'SR': 0.0}            NaN   \n",
      "7          16193.0                 {'NORM': 100.0, 'SR': 0.0}            NaN   \n",
      "9          18792.0                 {'NORM': 100.0, 'SR': 0.0}            NaN   \n",
      "...            ...                                        ...            ...   \n",
      "21831      11905.0                 {'NORM': 100.0, 'SR': 0.0}            NaN   \n",
      "21832       7954.0  {'LAFB': 100.0, 'IVCD': 100.0, 'SR': 0.0}            NaN   \n",
      "21834      20703.0   {'NORM': 100.0, 'ABQRS': 0.0, 'SR': 0.0}            NaN   \n",
      "21835      19311.0                 {'ISCAS': 50.0, 'SR': 0.0}            NaN   \n",
      "21837      11744.0                 {'NORM': 100.0, 'SR': 0.0}            NaN   \n",
      "\n",
      "       burst_noise electrodes_problems extra_beats pacemaker  strat_fold  \\\n",
      "ecg_id                                                                     \n",
      "1              NaN                 NaN         NaN       NaN           3   \n",
      "2              NaN                 NaN         NaN       NaN           2   \n",
      "3              NaN                 NaN         NaN       NaN           5   \n",
      "7              NaN                 NaN         NaN       NaN           7   \n",
      "9              NaN                 NaN         NaN       NaN          10   \n",
      "...            ...                 ...         ...       ...         ...   \n",
      "21831          NaN                 NaN         NaN       NaN           9   \n",
      "21832          NaN                 NaN         NaN       NaN           7   \n",
      "21834          NaN                 NaN         NaN       NaN           4   \n",
      "21835          NaN                 NaN         NaN       NaN           2   \n",
      "21837          NaN                 NaN         NaN       NaN           9   \n",
      "\n",
      "                      filename_hr  \n",
      "ecg_id                             \n",
      "1       records500/00000/00001_hr  \n",
      "2       records500/00000/00002_hr  \n",
      "3       records500/00000/00003_hr  \n",
      "7       records500/00000/00007_hr  \n",
      "9       records500/00000/00009_hr  \n",
      "...                           ...  \n",
      "21831   records500/21000/21831_hr  \n",
      "21832   records500/21000/21832_hr  \n",
      "21834   records500/21000/21834_hr  \n",
      "21835   records500/21000/21835_hr  \n",
      "21837   records500/21000/21837_hr  \n",
      "\n",
      "[17712 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "X = load_raw_data(Y, sampling_rate, path)\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv('/home/oopsie/Documents/PSIML/Projekat/physionet.org/scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    x=0\n",
    "    for key in y_dic.keys():\n",
    "        x+=1\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "    \n",
    "# Apply diagnostic superclass\n",
    "print(Y)\n",
    "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
    "249840\n",
    "# Split data into train and test\n",
    "test_fold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a1e5a1-c87a-42e3-a34a-ee25ace68fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Usage: 6050.11 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get the current process ID (PID)\n",
    "pid = psutil.Process()\n",
    "\n",
    "# Get the memory information\n",
    "memory_info = pid.memory_info()\n",
    "\n",
    "# RAM usage in bytes\n",
    "ram_usage_bytes = memory_info.rss\n",
    "\n",
    "# Convert bytes to megabytes (MB) for a more readable output\n",
    "ram_usage_mb = ram_usage_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"RAM Usage: {ram_usage_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd6e85c6-0dc9-437b-98c4-292d59d060c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8174\n",
      "4302\n",
      "4144\n",
      "3898\n",
      "2124\n"
     ]
    }
   ],
   "source": [
    "norm_count = Y['diagnostic_superclass'].apply(lambda x: x.count('NORM')).sum()\n",
    "print(norm_count)\n",
    "norm_count = Y['diagnostic_superclass'].apply(lambda x: x.count('MI')).sum()\n",
    "print(norm_count)\n",
    "norm_count = Y['diagnostic_superclass'].apply(lambda x: x.count('STTC')).sum()\n",
    "print(norm_count)\n",
    "norm_count = Y['diagnostic_superclass'].apply(lambda x: x.count('CD')).sum()\n",
    "print(norm_count)\n",
    "norm_count = Y['diagnostic_superclass'].apply(lambda x: x.count('HYP')).sum()\n",
    "print(norm_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "655f6b49-9f3b-40fe-82c2-8cb424f8e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['NORM']\n",
      "1 ['NORM']\n",
      "2 ['NORM']\n",
      "3 ['MI']\n",
      "4 ['CD']\n",
      "5 ['NORM']\n",
      "6 ['NORM']\n",
      "7 ['NORM']\n",
      "8 ['NORM']\n",
      "9 ['STTC']\n",
      "10 ['NORM']\n",
      "11 ['NORM']\n",
      "12 ['NORM']\n",
      "13 ['NORM']\n",
      "14 ['NORM']\n",
      "15 ['CD']\n",
      "16 ['STTC']\n",
      "17 ['STTC', 'HYP', 'CD', 'MI']\n",
      "18 ['STTC']\n",
      "19 ['CD']\n",
      "20 ['NORM']\n",
      "21 ['NORM']\n",
      "22 ['NORM']\n",
      "23 ['MI']\n",
      "24 ['CD', 'NORM']\n",
      "25 ['MI']\n",
      "26 ['NORM']\n",
      "27 ['NORM']\n",
      "28 ['STTC', 'HYP', 'MI']\n",
      "29 ['STTC', 'HYP', 'MI']\n",
      "30 ['STTC', 'HYP']\n",
      "31 ['STTC']\n",
      "32 ['NORM']\n",
      "33 ['STTC', 'HYP', 'CD']\n",
      "34 ['NORM']\n",
      "35 ['NORM']\n",
      "36 ['CD']\n",
      "37 ['CD']\n",
      "38 ['NORM']\n",
      "39 ['STTC']\n",
      "40 ['NORM']\n",
      "41 ['NORM']\n",
      "42 ['STTC']\n",
      "43 ['MI']\n",
      "44 ['NORM']\n",
      "45 ['CD']\n",
      "46 []\n",
      "47 ['NORM']\n",
      "48 ['CD', 'NORM']\n",
      "49 ['STTC']\n",
      "50 ['NORM']\n",
      "51 ['CD', 'MI']\n",
      "52 ['MI']\n",
      "53 ['STTC', 'HYP']\n",
      "54 ['NORM']\n",
      "55 ['STTC', 'CD']\n",
      "56 ['NORM']\n",
      "57 ['STTC', 'CD', 'MI']\n",
      "58 ['NORM']\n",
      "59 ['NORM']\n",
      "60 ['NORM']\n",
      "61 ['CD']\n",
      "62 ['NORM']\n",
      "63 ['CD']\n",
      "64 ['NORM']\n",
      "65 ['STTC', 'CD']\n",
      "66 ['NORM']\n",
      "67 ['NORM']\n",
      "68 ['STTC']\n",
      "69 ['STTC', 'MI']\n",
      "70 ['CD', 'NORM']\n",
      "71 ['NORM']\n",
      "72 ['NORM']\n",
      "73 ['NORM']\n",
      "74 ['NORM']\n",
      "75 ['MI']\n",
      "76 ['NORM']\n",
      "77 ['NORM']\n",
      "78 ['CD']\n",
      "79 ['NORM']\n",
      "80 ['NORM']\n",
      "81 ['CD']\n",
      "82 ['MI']\n",
      "83 ['NORM']\n",
      "84 ['STTC', 'MI']\n",
      "85 ['STTC']\n",
      "86 ['NORM']\n",
      "87 ['NORM']\n",
      "88 ['NORM']\n",
      "89 ['NORM']\n",
      "90 ['NORM']\n",
      "91 ['CD', 'NORM']\n",
      "92 ['NORM']\n",
      "93 ['HYP', 'MI']\n",
      "94 ['MI']\n",
      "95 ['NORM']\n",
      "96 ['CD']\n",
      "97 ['NORM']\n",
      "98 ['CD', 'MI']\n",
      "99 ['STTC']\n",
      "100 ['MI']\n",
      "101 ['STTC']\n",
      "102 ['STTC', 'HYP']\n",
      "103 ['CD', 'MI']\n",
      "104 ['NORM']\n",
      "105 ['NORM']\n",
      "106 ['NORM']\n",
      "107 ['NORM']\n",
      "108 ['CD', 'MI']\n",
      "109 ['NORM']\n",
      "110 ['STTC']\n",
      "111 ['NORM']\n",
      "112 ['NORM']\n",
      "113 ['STTC', 'CD', 'MI']\n",
      "114 ['NORM']\n",
      "115 ['NORM']\n",
      "116 ['NORM']\n",
      "117 ['NORM']\n",
      "118 ['CD']\n",
      "119 ['NORM']\n",
      "120 ['NORM']\n",
      "121 ['NORM']\n",
      "122 ['NORM']\n",
      "123 ['NORM']\n",
      "124 ['STTC']\n",
      "125 ['NORM']\n",
      "126 ['NORM']\n",
      "127 ['CD', 'MI']\n",
      "128 ['HYP']\n",
      "129 ['CD', 'NORM']\n",
      "130 ['NORM']\n",
      "131 ['NORM']\n",
      "132 ['NORM']\n",
      "133 ['STTC']\n",
      "134 ['NORM']\n",
      "135 ['HYP']\n",
      "136 ['MI']\n",
      "137 ['NORM']\n",
      "138 ['NORM']\n",
      "139 ['NORM']\n",
      "140 ['STTC']\n",
      "141 ['HYP']\n",
      "142 ['CD', 'MI']\n",
      "143 ['STTC']\n",
      "144 ['STTC']\n",
      "145 ['HYP', 'MI']\n",
      "146 ['NORM']\n",
      "147 ['NORM']\n",
      "148 ['NORM']\n",
      "149 ['NORM']\n",
      "150 ['NORM']\n",
      "151 ['HYP']\n",
      "152 ['HYP']\n",
      "153 ['HYP', 'MI']\n",
      "154 ['CD']\n",
      "155 ['CD', 'MI']\n",
      "156 ['NORM']\n",
      "157 ['NORM']\n",
      "158 ['STTC']\n",
      "159 ['NORM']\n",
      "160 ['NORM']\n",
      "161 ['NORM']\n",
      "162 ['NORM']\n",
      "163 ['NORM']\n",
      "164 ['NORM']\n",
      "165 ['NORM']\n",
      "166 ['NORM']\n",
      "167 ['STTC']\n",
      "168 ['MI']\n",
      "169 ['HYP']\n",
      "170 ['MI']\n",
      "171 ['MI']\n",
      "172 ['NORM']\n",
      "173 ['MI']\n",
      "174 ['NORM']\n",
      "175 ['NORM']\n",
      "176 ['HYP']\n",
      "177 ['NORM']\n",
      "178 ['STTC']\n",
      "179 ['MI']\n",
      "180 ['NORM']\n",
      "181 ['NORM']\n",
      "182 ['NORM']\n",
      "183 ['NORM']\n",
      "184 ['MI']\n",
      "185 ['NORM']\n",
      "186 ['NORM']\n",
      "187 ['NORM']\n",
      "188 ['NORM']\n",
      "189 ['NORM']\n",
      "190 ['NORM']\n",
      "191 ['MI']\n",
      "192 ['NORM']\n",
      "193 ['NORM']\n",
      "194 ['STTC', 'CD']\n",
      "195 ['STTC', 'MI']\n",
      "196 ['NORM']\n",
      "197 ['NORM']\n",
      "198 ['HYP', 'MI']\n",
      "199 ['NORM']\n",
      "200 ['NORM']\n",
      "201 ['STTC']\n",
      "202 ['STTC']\n",
      "203 ['NORM']\n",
      "204 ['STTC', 'MI']\n",
      "205 ['STTC', 'MI']\n",
      "206 ['STTC']\n",
      "207 ['NORM']\n",
      "208 ['STTC']\n",
      "209 ['STTC', 'HYP']\n",
      "210 ['STTC', 'HYP', 'MI']\n",
      "211 ['STTC']\n",
      "212 ['NORM']\n",
      "213 ['STTC']\n",
      "214 ['CD']\n",
      "215 ['NORM']\n",
      "216 ['STTC']\n",
      "217 ['STTC']\n",
      "218 ['STTC']\n",
      "219 ['NORM']\n",
      "220 ['NORM']\n",
      "221 ['NORM']\n",
      "222 ['STTC']\n",
      "223 ['STTC', 'HYP']\n",
      "224 ['STTC', 'MI']\n",
      "225 ['NORM']\n",
      "226 ['NORM']\n",
      "227 ['MI']\n",
      "228 ['NORM']\n",
      "229 ['CD']\n",
      "230 ['NORM']\n",
      "231 ['STTC', 'CD']\n",
      "232 ['CD']\n",
      "233 ['STTC']\n",
      "234 ['NORM']\n",
      "235 ['STTC', 'HYP']\n",
      "236 ['STTC', 'HYP', 'MI']\n",
      "237 ['HYP', 'CD', 'MI']\n",
      "238 ['NORM']\n",
      "239 ['CD', 'MI']\n",
      "240 ['NORM']\n",
      "241 ['CD', 'NORM']\n",
      "242 ['NORM']\n",
      "243 ['CD']\n",
      "244 ['CD']\n",
      "245 ['NORM']\n",
      "246 ['NORM']\n",
      "247 ['NORM']\n",
      "248 ['STTC']\n",
      "249 ['STTC']\n",
      "250 ['CD', 'HYP']\n",
      "251 ['NORM']\n",
      "252 ['HYP']\n",
      "253 ['CD']\n",
      "254 ['MI']\n",
      "255 ['NORM']\n",
      "256 ['NORM']\n",
      "257 ['NORM']\n",
      "258 ['HYP']\n",
      "259 ['NORM']\n",
      "260 ['STTC', 'MI']\n",
      "261 ['CD', 'NORM']\n",
      "262 ['NORM']\n",
      "263 ['STTC']\n",
      "264 ['NORM']\n",
      "265 ['MI']\n",
      "266 ['STTC', 'HYP']\n",
      "267 ['NORM']\n",
      "268 ['STTC', 'MI']\n",
      "269 ['STTC', 'HYP']\n",
      "270 ['CD', 'MI']\n",
      "271 ['CD']\n",
      "272 ['MI']\n",
      "273 ['NORM']\n",
      "274 ['NORM']\n",
      "275 ['STTC']\n",
      "276 ['NORM']\n",
      "277 ['CD']\n",
      "278 ['STTC']\n",
      "279 ['MI']\n",
      "280 ['NORM']\n",
      "281 ['CD', 'NORM']\n",
      "282 ['MI']\n",
      "283 ['NORM']\n",
      "284 ['NORM']\n",
      "285 ['NORM']\n",
      "286 ['NORM']\n",
      "287 ['STTC', 'HYP', 'MI']\n",
      "288 ['NORM']\n",
      "289 ['NORM']\n",
      "290 ['NORM']\n",
      "291 ['NORM']\n",
      "292 ['NORM']\n",
      "293 ['STTC']\n",
      "294 ['NORM']\n",
      "295 ['CD', 'NORM']\n",
      "296 ['CD', 'NORM']\n",
      "297 ['NORM']\n",
      "298 ['NORM']\n",
      "299 ['NORM']\n",
      "300 ['STTC']\n",
      "301 ['NORM']\n",
      "302 ['STTC']\n",
      "303 ['NORM']\n",
      "304 ['NORM']\n",
      "305 ['NORM']\n",
      "306 ['NORM']\n",
      "307 ['NORM']\n",
      "308 ['NORM']\n",
      "309 ['STTC', 'MI']\n",
      "310 ['NORM']\n",
      "311 ['NORM']\n",
      "312 ['STTC']\n",
      "313 ['CD', 'NORM']\n",
      "314 ['NORM']\n",
      "315 ['NORM']\n",
      "316 ['NORM']\n",
      "317 ['STTC']\n",
      "318 ['NORM']\n",
      "319 ['NORM']\n",
      "320 ['NORM']\n",
      "321 ['MI']\n",
      "322 ['NORM']\n",
      "323 ['NORM']\n",
      "324 ['NORM']\n",
      "325 ['NORM']\n",
      "326 ['NORM']\n",
      "327 ['NORM']\n",
      "328 ['CD']\n",
      "329 ['STTC', 'MI']\n",
      "330 ['STTC']\n",
      "331 ['NORM']\n",
      "332 ['MI']\n",
      "333 ['CD', 'MI']\n",
      "334 ['CD', 'NORM']\n",
      "335 ['STTC', 'MI']\n",
      "336 ['STTC', 'HYP', 'CD', 'MI']\n",
      "337 ['STTC', 'HYP']\n",
      "338 ['STTC']\n",
      "339 ['CD', 'NORM']\n",
      "340 ['MI']\n",
      "341 ['STTC']\n",
      "342 ['NORM']\n",
      "343 ['MI']\n",
      "344 ['STTC']\n",
      "345 ['CD']\n",
      "346 ['HYP']\n",
      "347 ['NORM']\n",
      "348 ['NORM']\n",
      "349 ['NORM']\n",
      "350 ['NORM']\n",
      "351 ['STTC', 'HYP', 'MI']\n",
      "352 ['CD', 'HYP', 'NORM']\n",
      "353 ['NORM']\n",
      "354 ['NORM']\n",
      "355 ['NORM']\n",
      "356 ['STTC']\n",
      "357 ['NORM']\n",
      "358 ['NORM']\n",
      "359 ['NORM']\n",
      "360 ['NORM']\n",
      "361 ['MI']\n",
      "362 ['NORM']\n",
      "363 ['CD', 'MI']\n",
      "364 ['MI']\n",
      "365 ['CD', 'MI']\n",
      "366 ['NORM']\n",
      "367 ['STTC']\n",
      "368 ['MI']\n",
      "369 ['HYP', 'MI']\n",
      "370 ['MI']\n",
      "371 ['STTC']\n",
      "372 ['NORM']\n",
      "373 ['NORM']\n",
      "374 ['NORM']\n",
      "375 ['CD', 'MI']\n",
      "376 ['MI']\n",
      "377 ['NORM']\n",
      "378 ['NORM']\n",
      "379 ['NORM']\n",
      "380 ['NORM']\n",
      "381 ['NORM']\n",
      "382 ['CD', 'HYP']\n",
      "383 ['STTC', 'MI']\n",
      "384 ['STTC', 'MI']\n",
      "385 ['MI']\n",
      "386 ['NORM']\n",
      "387 ['NORM']\n",
      "388 ['NORM']\n",
      "389 ['CD', 'NORM']\n",
      "390 ['NORM']\n",
      "391 ['HYP']\n",
      "392 ['CD']\n",
      "393 ['STTC', 'HYP']\n",
      "394 ['CD', 'MI']\n",
      "395 ['STTC', 'HYP']\n",
      "396 ['STTC', 'HYP']\n",
      "397 ['NORM']\n",
      "398 ['STTC', 'HYP']\n",
      "399 ['MI']\n",
      "400 ['NORM']\n",
      "401 ['STTC', 'HYP', 'MI']\n",
      "402 ['MI']\n",
      "403 ['NORM']\n",
      "404 ['NORM']\n",
      "405 ['NORM']\n",
      "406 ['CD']\n",
      "407 ['CD']\n",
      "408 ['MI']\n",
      "409 ['NORM']\n",
      "410 ['NORM']\n",
      "411 ['CD']\n",
      "412 ['NORM']\n",
      "413 ['NORM']\n",
      "414 ['CD']\n",
      "415 ['STTC', 'MI']\n",
      "416 ['NORM']\n",
      "417 ['NORM']\n",
      "418 ['MI']\n",
      "419 ['STTC']\n",
      "420 ['MI']\n",
      "421 ['CD', 'HYP', 'NORM']\n",
      "422 ['MI']\n",
      "423 ['MI']\n",
      "424 ['CD']\n",
      "425 ['NORM']\n",
      "426 ['MI']\n",
      "427 ['CD']\n",
      "428 ['STTC']\n",
      "429 ['NORM']\n",
      "430 ['CD']\n",
      "431 ['NORM']\n",
      "432 ['CD', 'NORM']\n",
      "433 ['CD']\n",
      "434 ['MI']\n",
      "435 ['NORM']\n",
      "436 ['MI']\n",
      "437 ['HYP']\n",
      "438 ['NORM']\n",
      "439 ['STTC', 'HYP', 'CD']\n",
      "440 ['NORM']\n",
      "441 ['MI']\n",
      "442 ['HYP', 'CD']\n",
      "443 ['MI']\n",
      "444 ['NORM']\n",
      "445 ['NORM']\n",
      "446 ['CD']\n",
      "447 ['CD']\n",
      "448 ['MI']\n",
      "449 ['HYP']\n",
      "450 ['STTC']\n",
      "451 ['STTC']\n",
      "452 ['NORM']\n",
      "453 ['STTC']\n",
      "454 ['MI']\n",
      "455 ['NORM']\n",
      "456 ['HYP', 'CD']\n",
      "457 ['HYP']\n",
      "458 ['NORM']\n",
      "459 ['CD']\n",
      "460 ['NORM']\n",
      "461 ['MI']\n",
      "462 ['HYP', 'CD']\n",
      "463 ['NORM']\n",
      "464 ['STTC', 'HYP', 'MI']\n",
      "465 ['MI']\n",
      "466 ['STTC', 'CD', 'MI']\n",
      "467 ['CD']\n",
      "468 ['STTC', 'MI']\n",
      "469 ['STTC', 'HYP', 'MI']\n",
      "470 ['STTC', 'CD']\n",
      "471 ['STTC']\n",
      "472 ['NORM']\n",
      "473 ['NORM']\n",
      "474 ['NORM']\n",
      "475 ['STTC', 'HYP', 'MI']\n",
      "476 ['STTC', 'MI']\n",
      "477 ['CD']\n",
      "478 ['STTC']\n",
      "479 ['CD']\n",
      "480 ['NORM']\n",
      "481 ['STTC']\n",
      "482 ['NORM']\n",
      "483 ['CD']\n",
      "484 ['MI']\n",
      "485 ['CD']\n",
      "486 ['NORM']\n",
      "487 ['STTC']\n",
      "488 ['NORM']\n",
      "489 ['NORM']\n",
      "490 ['NORM']\n",
      "491 ['STTC', 'NORM']\n",
      "492 ['STTC', 'HYP', 'CD']\n",
      "493 ['NORM']\n",
      "494 ['CD', 'MI']\n",
      "495 ['STTC']\n",
      "496 ['NORM']\n",
      "497 ['STTC', 'HYP']\n",
      "498 ['NORM']\n",
      "499 ['CD', 'NORM']\n",
      "500 ['STTC']\n",
      "501 ['NORM']\n",
      "502 ['MI']\n",
      "503 ['NORM']\n",
      "504 ['CD', 'MI']\n",
      "505 ['MI']\n",
      "506 ['STTC', 'HYP', 'CD', 'MI']\n",
      "507 ['CD']\n",
      "508 ['NORM']\n",
      "509 ['NORM']\n",
      "510 ['MI']\n",
      "511 ['NORM']\n",
      "512 ['CD', 'MI']\n",
      "513 []\n",
      "514 ['NORM']\n",
      "515 ['NORM']\n",
      "516 ['MI']\n",
      "517 ['STTC']\n",
      "518 ['NORM']\n",
      "519 ['STTC', 'HYP']\n",
      "520 ['NORM']\n",
      "521 ['NORM']\n",
      "522 ['NORM']\n",
      "523 ['NORM']\n",
      "524 ['CD']\n",
      "525 ['HYP', 'CD']\n",
      "526 ['STTC', 'MI']\n",
      "527 ['MI']\n",
      "528 ['NORM']\n",
      "529 ['NORM']\n",
      "530 ['MI']\n",
      "531 ['NORM']\n",
      "532 ['MI']\n",
      "533 ['NORM']\n",
      "534 ['NORM']\n",
      "535 ['NORM']\n",
      "536 ['NORM']\n",
      "537 ['NORM']\n",
      "538 ['NORM']\n",
      "539 ['STTC']\n",
      "540 ['NORM']\n",
      "541 ['NORM']\n",
      "542 ['STTC', 'CD']\n",
      "543 ['MI']\n",
      "544 ['MI']\n",
      "545 ['NORM']\n",
      "546 ['NORM']\n",
      "547 ['CD', 'NORM']\n",
      "548 ['NORM']\n",
      "549 ['MI']\n",
      "550 ['NORM']\n",
      "551 ['HYP', 'CD']\n",
      "552 ['MI']\n",
      "553 ['STTC', 'HYP', 'MI']\n",
      "554 ['NORM']\n",
      "555 ['NORM']\n",
      "556 ['CD', 'MI']\n",
      "557 ['HYP']\n",
      "558 ['NORM']\n",
      "559 ['NORM']\n",
      "560 ['NORM']\n",
      "561 ['STTC']\n",
      "562 ['NORM']\n",
      "563 ['CD', 'MI']\n",
      "564 ['STTC', 'HYP']\n",
      "565 ['STTC']\n",
      "566 ['STTC']\n",
      "567 ['STTC', 'MI']\n",
      "568 ['HYP']\n",
      "569 ['NORM']\n",
      "570 ['NORM']\n",
      "571 ['NORM']\n",
      "572 ['NORM']\n",
      "573 ['NORM']\n",
      "574 ['NORM']\n",
      "575 ['NORM']\n",
      "576 ['HYP', 'CD']\n",
      "577 ['CD']\n",
      "578 ['NORM']\n",
      "579 ['NORM']\n",
      "580 ['NORM']\n",
      "581 ['NORM']\n",
      "582 ['CD', 'MI']\n",
      "583 ['NORM']\n",
      "584 ['NORM']\n",
      "585 ['NORM']\n",
      "586 ['CD', 'MI']\n",
      "587 ['NORM']\n",
      "588 ['NORM']\n",
      "589 ['CD']\n",
      "590 ['NORM']\n",
      "591 ['STTC', 'CD', 'MI']\n",
      "592 ['NORM']\n",
      "593 ['STTC', 'HYP']\n",
      "594 ['CD']\n",
      "595 ['CD']\n",
      "596 ['HYP']\n",
      "597 ['STTC', 'MI']\n",
      "598 ['NORM']\n",
      "599 ['STTC']\n",
      "600 ['STTC']\n",
      "601 ['NORM']\n",
      "602 ['STTC']\n",
      "603 ['NORM']\n",
      "604 ['STTC', 'MI']\n",
      "605 ['MI']\n",
      "606 ['NORM']\n",
      "607 ['MI']\n",
      "608 ['MI']\n",
      "609 ['NORM']\n",
      "610 ['NORM']\n",
      "611 ['CD', 'MI']\n",
      "612 ['NORM']\n",
      "613 ['NORM']\n",
      "614 ['STTC']\n",
      "615 ['MI']\n",
      "616 ['CD']\n",
      "617 ['NORM']\n",
      "618 ['STTC']\n",
      "619 ['MI']\n",
      "620 ['NORM']\n",
      "621 ['STTC', 'CD', 'MI']\n",
      "622 ['STTC']\n",
      "623 ['NORM']\n",
      "624 ['STTC', 'MI']\n",
      "625 ['STTC', 'CD']\n",
      "626 ['STTC', 'HYP', 'MI']\n",
      "627 ['CD', 'NORM']\n",
      "628 ['CD']\n",
      "629 ['HYP']\n",
      "630 ['CD', 'MI']\n",
      "631 ['HYP']\n",
      "632 ['NORM']\n",
      "633 ['NORM']\n",
      "634 ['CD', 'HYP']\n",
      "635 ['NORM']\n",
      "636 ['NORM']\n",
      "637 ['CD']\n",
      "638 ['MI']\n",
      "639 ['MI']\n",
      "640 ['CD']\n",
      "641 ['NORM']\n",
      "642 ['CD']\n",
      "643 ['STTC']\n",
      "644 ['STTC', 'CD']\n",
      "645 ['HYP', 'MI']\n",
      "646 ['NORM']\n",
      "647 ['NORM']\n",
      "648 ['MI']\n",
      "649 ['NORM']\n",
      "650 ['STTC']\n",
      "651 ['MI']\n",
      "652 ['NORM']\n",
      "653 ['STTC', 'HYP', 'MI']\n",
      "654 ['HYP', 'MI']\n",
      "655 ['STTC']\n",
      "656 ['MI']\n",
      "657 ['STTC', 'CD', 'MI']\n",
      "658 ['NORM']\n",
      "659 ['MI']\n",
      "660 ['NORM']\n",
      "661 ['STTC']\n",
      "662 ['HYP', 'MI']\n",
      "663 ['MI']\n",
      "664 ['NORM']\n",
      "665 ['MI']\n",
      "666 ['NORM']\n",
      "667 ['MI']\n",
      "668 ['STTC']\n",
      "669 ['NORM']\n",
      "670 ['NORM']\n",
      "671 ['STTC', 'CD']\n",
      "672 ['NORM']\n",
      "673 ['CD']\n",
      "674 ['CD']\n",
      "675 ['NORM']\n",
      "676 ['MI']\n",
      "677 ['NORM']\n",
      "678 ['NORM']\n",
      "679 ['NORM']\n",
      "680 ['NORM']\n",
      "681 []\n",
      "682 ['STTC', 'HYP']\n",
      "683 ['NORM']\n",
      "684 ['NORM']\n",
      "685 ['NORM']\n",
      "686 ['NORM']\n",
      "687 ['HYP']\n",
      "688 ['NORM']\n",
      "689 ['CD', 'NORM']\n",
      "690 ['NORM']\n",
      "691 ['STTC', 'MI']\n",
      "692 ['STTC', 'HYP', 'MI']\n",
      "693 ['NORM']\n",
      "694 ['STTC']\n",
      "695 ['NORM']\n",
      "696 ['NORM']\n",
      "697 ['NORM']\n",
      "698 ['NORM']\n",
      "699 ['STTC', 'HYP', 'CD']\n",
      "700 ['STTC', 'HYP', 'CD']\n",
      "701 ['NORM']\n",
      "702 ['NORM']\n",
      "703 ['HYP', 'CD', 'MI']\n",
      "704 ['CD', 'MI']\n",
      "705 ['HYP']\n",
      "706 ['HYP']\n",
      "707 ['STTC', 'MI']\n",
      "708 ['STTC', 'HYP', 'CD', 'MI']\n",
      "709 ['MI']\n",
      "710 ['MI']\n",
      "711 ['MI']\n",
      "712 ['STTC']\n",
      "713 ['HYP', 'CD']\n",
      "714 ['NORM']\n",
      "715 ['NORM']\n",
      "716 ['HYP']\n",
      "717 ['CD', 'MI']\n",
      "718 ['NORM']\n",
      "719 ['STTC', 'HYP', 'MI']\n",
      "720 ['NORM']\n",
      "721 ['NORM']\n",
      "722 ['STTC', 'HYP', 'MI']\n",
      "723 ['STTC', 'HYP', 'CD']\n",
      "724 ['CD', 'MI']\n",
      "725 ['NORM']\n",
      "726 ['STTC', 'MI']\n",
      "727 ['HYP', 'CD']\n",
      "728 []\n",
      "729 ['NORM']\n",
      "730 ['MI']\n",
      "731 ['NORM']\n",
      "732 ['HYP']\n",
      "733 ['STTC', 'HYP', 'CD']\n",
      "734 ['STTC', 'CD']\n",
      "735 ['NORM']\n",
      "736 ['STTC']\n",
      "737 ['STTC', 'HYP', 'CD']\n",
      "738 ['CD']\n",
      "739 ['STTC']\n",
      "740 ['MI']\n",
      "741 ['STTC']\n",
      "742 ['STTC', 'MI']\n",
      "743 ['STTC']\n",
      "744 ['CD', 'MI']\n",
      "745 ['CD']\n",
      "746 ['NORM']\n",
      "747 ['HYP']\n",
      "748 ['STTC']\n",
      "749 ['NORM']\n",
      "750 ['HYP']\n",
      "751 ['NORM']\n",
      "752 ['CD', 'MI']\n",
      "753 ['NORM']\n",
      "754 ['STTC']\n",
      "755 ['NORM']\n",
      "756 ['STTC', 'CD']\n",
      "757 ['NORM']\n",
      "758 ['NORM']\n",
      "759 ['NORM']\n",
      "760 ['NORM']\n",
      "761 ['CD', 'MI']\n",
      "762 ['CD']\n",
      "763 ['MI']\n",
      "764 ['NORM']\n",
      "765 ['NORM']\n",
      "766 ['STTC', 'HYP']\n",
      "767 ['STTC']\n",
      "768 []\n",
      "769 ['CD', 'MI']\n",
      "770 ['NORM']\n",
      "771 ['NORM']\n",
      "772 ['STTC', 'HYP', 'MI']\n",
      "773 ['STTC']\n",
      "774 ['CD', 'HYP']\n",
      "775 ['NORM']\n",
      "776 ['NORM']\n",
      "777 ['MI']\n",
      "778 ['STTC', 'HYP']\n",
      "779 ['CD', 'NORM']\n",
      "780 ['NORM']\n",
      "781 ['CD', 'MI']\n",
      "782 ['CD', 'MI']\n",
      "783 ['HYP']\n",
      "784 ['MI']\n",
      "785 ['STTC', 'HYP', 'CD', 'MI']\n",
      "786 ['NORM']\n",
      "787 ['MI']\n",
      "788 ['STTC', 'MI']\n",
      "789 ['CD', 'MI']\n",
      "790 ['STTC']\n",
      "791 ['STTC']\n",
      "792 []\n",
      "793 ['CD', 'MI']\n",
      "794 ['STTC', 'HYP']\n",
      "795 ['NORM']\n",
      "796 ['NORM']\n",
      "797 ['STTC', 'HYP']\n",
      "798 ['CD']\n",
      "799 ['HYP']\n",
      "800 ['STTC']\n",
      "801 ['NORM']\n",
      "802 ['NORM']\n",
      "803 ['NORM']\n",
      "804 ['STTC']\n",
      "805 ['MI']\n",
      "806 ['CD']\n",
      "807 ['STTC']\n",
      "808 ['CD']\n",
      "809 ['NORM']\n",
      "810 ['NORM']\n",
      "811 ['STTC', 'HYP']\n",
      "812 ['CD']\n",
      "813 ['NORM']\n",
      "814 ['STTC', 'MI']\n",
      "815 ['STTC']\n",
      "816 ['NORM']\n",
      "817 ['HYP', 'MI']\n",
      "818 ['NORM']\n",
      "819 ['HYP']\n",
      "820 ['NORM']\n",
      "821 ['STTC']\n",
      "822 ['STTC', 'CD']\n",
      "823 ['CD', 'NORM']\n",
      "824 ['NORM']\n",
      "825 ['STTC']\n",
      "826 ['NORM']\n",
      "827 ['NORM']\n",
      "828 ['STTC', 'HYP', 'CD', 'MI']\n",
      "829 ['HYP', 'MI']\n",
      "830 ['CD', 'HYP']\n",
      "831 ['NORM']\n",
      "832 ['NORM']\n",
      "833 ['NORM']\n",
      "834 ['NORM']\n",
      "835 ['NORM']\n",
      "836 ['HYP']\n",
      "837 ['NORM']\n",
      "838 ['NORM']\n",
      "839 ['HYP', 'CD']\n",
      "840 ['CD', 'MI']\n",
      "841 ['STTC', 'HYP']\n",
      "842 ['CD']\n",
      "843 ['HYP', 'CD']\n",
      "844 ['STTC']\n",
      "845 ['NORM']\n",
      "846 ['CD', 'MI']\n",
      "847 ['NORM']\n",
      "848 ['STTC']\n",
      "849 ['NORM']\n",
      "850 ['STTC']\n",
      "851 ['NORM']\n",
      "852 ['STTC', 'HYP', 'MI']\n",
      "853 ['CD']\n",
      "854 ['STTC']\n",
      "855 ['CD']\n",
      "856 ['NORM']\n",
      "857 ['STTC']\n",
      "858 ['CD', 'MI']\n",
      "859 ['NORM']\n",
      "860 ['NORM']\n",
      "861 ['NORM']\n",
      "862 ['HYP']\n",
      "863 ['NORM']\n",
      "864 ['NORM']\n",
      "865 ['CD', 'MI']\n",
      "866 ['NORM']\n",
      "867 ['CD', 'MI']\n",
      "868 ['MI']\n",
      "869 ['NORM']\n",
      "870 ['NORM']\n",
      "871 ['STTC', 'CD', 'MI']\n",
      "872 ['CD']\n",
      "873 ['CD', 'MI']\n",
      "874 ['NORM']\n",
      "875 ['CD', 'MI']\n",
      "876 ['STTC', 'HYP', 'MI']\n",
      "877 ['NORM']\n",
      "878 ['NORM']\n",
      "879 ['STTC']\n",
      "880 ['STTC', 'MI']\n",
      "881 ['NORM']\n",
      "882 ['NORM']\n",
      "883 ['STTC']\n",
      "884 ['NORM']\n",
      "885 ['NORM']\n",
      "886 ['STTC', 'HYP', 'MI']\n",
      "887 ['CD', 'MI']\n",
      "888 ['STTC']\n",
      "889 ['MI']\n",
      "890 ['NORM']\n",
      "891 ['CD']\n",
      "892 ['STTC']\n",
      "893 ['NORM']\n",
      "894 ['MI']\n",
      "895 ['STTC']\n",
      "896 ['NORM']\n",
      "897 ['STTC']\n",
      "898 ['STTC', 'HYP', 'CD']\n",
      "899 ['MI']\n",
      "900 ['CD', 'MI']\n",
      "901 ['MI']\n",
      "902 ['NORM']\n",
      "903 ['STTC']\n",
      "904 ['CD', 'MI']\n",
      "905 ['NORM']\n",
      "906 ['NORM']\n",
      "907 ['MI']\n",
      "908 ['CD']\n",
      "909 ['NORM']\n",
      "910 ['NORM']\n",
      "911 ['NORM']\n",
      "912 ['NORM']\n",
      "913 ['NORM']\n",
      "914 ['NORM']\n",
      "915 ['STTC']\n",
      "916 ['STTC', 'HYP', 'CD']\n",
      "917 ['STTC', 'MI']\n",
      "918 ['NORM']\n",
      "919 ['STTC', 'HYP']\n",
      "920 ['CD']\n",
      "921 ['NORM']\n",
      "922 ['NORM']\n",
      "923 ['NORM']\n",
      "924 ['NORM']\n",
      "925 ['STTC']\n",
      "926 ['STTC', 'HYP']\n",
      "927 ['HYP']\n",
      "928 ['NORM']\n",
      "929 ['STTC']\n",
      "930 ['STTC']\n",
      "931 ['HYP']\n",
      "932 ['NORM']\n",
      "933 ['MI']\n",
      "934 ['NORM']\n",
      "935 ['NORM']\n",
      "936 ['NORM']\n",
      "937 ['MI']\n",
      "938 ['NORM']\n",
      "939 ['CD', 'NORM']\n",
      "940 ['NORM']\n",
      "941 ['NORM']\n",
      "942 ['CD']\n",
      "943 ['NORM']\n",
      "944 ['NORM']\n",
      "945 ['STTC', 'CD']\n",
      "946 ['STTC']\n",
      "947 ['STTC', 'HYP', 'CD']\n",
      "948 ['NORM']\n",
      "949 ['CD']\n",
      "950 ['NORM']\n",
      "951 ['CD']\n",
      "952 ['HYP']\n",
      "953 ['STTC', 'CD']\n",
      "954 ['NORM']\n",
      "955 ['NORM']\n",
      "956 ['CD']\n",
      "957 ['NORM']\n",
      "958 ['NORM']\n",
      "959 ['NORM']\n",
      "960 ['STTC', 'HYP', 'CD']\n",
      "961 ['NORM']\n",
      "962 ['NORM']\n",
      "963 ['STTC', 'HYP']\n",
      "964 ['NORM']\n",
      "965 ['MI']\n",
      "966 ['STTC', 'MI']\n",
      "967 ['STTC']\n",
      "968 ['CD', 'MI']\n",
      "969 ['STTC', 'CD']\n",
      "970 ['NORM']\n",
      "971 ['STTC']\n",
      "972 ['NORM']\n",
      "973 ['NORM']\n",
      "974 ['NORM']\n",
      "975 ['STTC']\n",
      "976 ['NORM']\n",
      "977 ['NORM']\n",
      "978 ['CD']\n",
      "979 ['NORM']\n",
      "980 ['STTC', 'HYP', 'CD', 'MI']\n",
      "981 ['NORM']\n",
      "982 ['CD']\n",
      "983 ['CD', 'MI']\n",
      "984 ['NORM']\n",
      "985 ['STTC']\n",
      "986 ['STTC', 'HYP', 'CD', 'MI']\n",
      "987 ['NORM']\n",
      "988 ['STTC', 'MI']\n",
      "989 ['NORM']\n",
      "990 ['MI']\n",
      "991 ['HYP', 'CD']\n",
      "992 ['STTC']\n",
      "993 ['NORM']\n",
      "994 ['NORM']\n",
      "995 ['NORM']\n",
      "996 ['CD']\n",
      "997 ['MI']\n",
      "998 ['NORM']\n",
      "999 ['NORM']\n",
      "1000 ['STTC', 'HYP']\n",
      "1001 ['STTC', 'HYP', 'MI']\n",
      "1002 ['NORM']\n",
      "1003 ['NORM']\n",
      "1004 ['STTC', 'CD']\n",
      "1005 ['MI']\n",
      "1006 ['MI']\n",
      "1007 ['MI']\n",
      "1008 ['CD', 'MI']\n",
      "1009 ['MI']\n",
      "1010 ['NORM']\n",
      "1011 ['NORM']\n",
      "1012 ['MI']\n",
      "1013 ['NORM']\n",
      "1014 ['STTC']\n",
      "1015 ['HYP', 'CD']\n",
      "1016 ['MI']\n",
      "1017 ['CD']\n",
      "1018 ['NORM']\n",
      "1019 ['NORM']\n",
      "1020 ['CD', 'MI']\n",
      "1021 ['NORM']\n",
      "1022 ['NORM']\n",
      "1023 ['NORM']\n",
      "1024 ['NORM']\n",
      "1025 ['CD', 'MI']\n",
      "1026 ['STTC', 'MI']\n",
      "1027 ['STTC']\n",
      "1028 ['MI']\n",
      "1029 ['MI']\n",
      "1030 ['NORM']\n",
      "1031 ['STTC', 'HYP', 'CD']\n",
      "1032 ['NORM']\n",
      "1033 ['NORM']\n",
      "1034 ['CD']\n",
      "1035 ['NORM']\n",
      "1036 ['STTC', 'HYP', 'MI']\n",
      "1037 ['STTC']\n",
      "1038 ['MI']\n",
      "1039 ['CD', 'NORM']\n",
      "1040 ['NORM']\n",
      "1041 ['CD', 'MI']\n",
      "1042 ['CD']\n",
      "1043 ['NORM']\n",
      "1044 ['NORM']\n",
      "1045 ['NORM']\n",
      "1046 ['STTC', 'MI']\n",
      "1047 ['HYP', 'MI']\n",
      "1048 ['NORM']\n",
      "1049 ['MI']\n",
      "1050 ['STTC', 'HYP']\n",
      "1051 ['STTC']\n",
      "1052 ['CD', 'NORM']\n",
      "1053 ['NORM']\n",
      "1054 ['NORM']\n",
      "1055 ['STTC', 'CD', 'MI']\n",
      "1056 ['NORM']\n",
      "1057 ['HYP']\n",
      "1058 ['NORM']\n",
      "1059 ['NORM']\n",
      "1060 ['NORM']\n",
      "1061 ['MI']\n",
      "1062 ['HYP']\n",
      "1063 ['MI']\n",
      "1064 ['STTC']\n",
      "1065 ['MI']\n",
      "1066 ['CD', 'MI']\n",
      "1067 ['NORM']\n",
      "1068 ['NORM']\n",
      "1069 ['MI']\n",
      "1070 ['NORM']\n",
      "1071 ['CD']\n",
      "1072 ['CD', 'NORM']\n",
      "1073 ['NORM']\n",
      "1074 ['CD', 'MI']\n",
      "1075 ['MI']\n",
      "1076 ['HYP', 'CD']\n",
      "1077 ['CD']\n",
      "1078 ['MI']\n",
      "1079 ['NORM']\n",
      "1080 ['MI']\n",
      "1081 ['NORM']\n",
      "1082 ['CD', 'MI']\n",
      "1083 ['NORM']\n",
      "1084 ['CD', 'MI']\n",
      "1085 ['CD', 'MI']\n",
      "1086 ['STTC', 'HYP']\n",
      "1087 ['NORM']\n",
      "1088 ['CD', 'MI']\n",
      "1089 ['CD', 'NORM']\n",
      "1090 ['NORM']\n",
      "1091 ['STTC', 'CD']\n",
      "1092 ['HYP']\n",
      "1093 ['NORM']\n",
      "1094 ['MI']\n",
      "1095 ['NORM']\n",
      "1096 ['STTC', 'HYP']\n",
      "1097 ['MI']\n",
      "1098 ['NORM']\n",
      "1099 ['NORM']\n",
      "1100 ['STTC']\n",
      "1101 ['NORM']\n",
      "1102 ['NORM']\n",
      "1103 ['CD']\n",
      "1104 ['NORM']\n",
      "1105 ['NORM']\n",
      "1106 ['NORM']\n",
      "1107 ['NORM']\n",
      "1108 ['NORM']\n",
      "1109 ['NORM']\n",
      "1110 ['STTC']\n",
      "1111 ['NORM']\n",
      "1112 ['NORM']\n",
      "1113 ['NORM']\n",
      "1114 ['STTC', 'MI']\n",
      "1115 ['STTC', 'MI']\n",
      "1116 ['CD']\n",
      "1117 ['STTC']\n",
      "1118 ['NORM']\n",
      "1119 ['STTC', 'HYP']\n",
      "1120 ['STTC']\n",
      "1121 ['NORM']\n",
      "1122 ['NORM']\n",
      "1123 ['NORM']\n",
      "1124 ['NORM']\n",
      "1125 ['MI']\n",
      "1126 ['CD', 'MI']\n",
      "1127 ['STTC', 'HYP']\n",
      "1128 ['NORM']\n",
      "1129 ['STTC', 'HYP', 'CD']\n",
      "1130 ['HYP']\n",
      "1131 ['NORM']\n",
      "1132 ['NORM']\n",
      "1133 ['CD']\n",
      "1134 ['NORM']\n",
      "1135 ['CD', 'MI']\n",
      "1136 ['NORM']\n",
      "1137 ['NORM']\n",
      "1138 ['HYP', 'MI']\n",
      "1139 ['NORM']\n",
      "1140 ['STTC', 'MI']\n",
      "1141 ['STTC', 'CD']\n",
      "1142 ['STTC']\n",
      "1143 ['CD']\n",
      "1144 ['CD', 'MI']\n",
      "1145 ['MI']\n",
      "1146 ['NORM']\n",
      "1147 ['MI']\n",
      "1148 ['MI']\n",
      "1149 ['NORM']\n",
      "1150 ['CD', 'NORM']\n",
      "1151 ['NORM']\n",
      "1152 ['CD', 'MI']\n",
      "1153 ['CD']\n",
      "1154 ['MI']\n",
      "1155 ['MI']\n",
      "1156 ['NORM']\n",
      "1157 ['NORM']\n",
      "1158 ['STTC']\n",
      "1159 ['NORM']\n",
      "1160 ['NORM']\n",
      "1161 ['NORM']\n",
      "1162 ['CD', 'NORM']\n",
      "1163 ['MI']\n",
      "1164 ['NORM']\n",
      "1165 ['STTC', 'HYP', 'CD']\n",
      "1166 ['STTC']\n",
      "1167 ['STTC']\n",
      "1168 ['NORM']\n",
      "1169 ['MI']\n",
      "1170 ['CD']\n",
      "1171 ['NORM']\n",
      "1172 ['CD']\n",
      "1173 ['STTC', 'MI']\n",
      "1174 ['STTC', 'HYP', 'MI']\n",
      "1175 ['STTC']\n",
      "1176 ['NORM']\n",
      "1177 ['NORM']\n",
      "1178 ['NORM']\n",
      "1179 ['STTC', 'HYP']\n",
      "1180 ['CD', 'NORM']\n",
      "1181 ['CD', 'MI']\n",
      "1182 ['NORM']\n",
      "1183 ['STTC']\n",
      "1184 ['NORM']\n",
      "1185 ['NORM']\n",
      "1186 ['STTC']\n",
      "1187 ['NORM']\n",
      "1188 ['NORM']\n",
      "1189 ['MI']\n",
      "1190 ['STTC']\n",
      "1191 ['NORM']\n",
      "1192 ['STTC', 'HYP', 'CD', 'MI']\n",
      "1193 ['STTC', 'MI']\n",
      "1194 ['CD']\n",
      "1195 ['HYP']\n",
      "1196 ['NORM']\n",
      "1197 ['NORM']\n",
      "1198 ['MI']\n",
      "1199 ['NORM']\n",
      "1200 ['NORM']\n",
      "1201 ['CD', 'NORM']\n",
      "1202 ['MI']\n",
      "1203 ['NORM']\n",
      "1204 ['CD', 'MI']\n",
      "1205 ['STTC', 'CD', 'MI']\n",
      "1206 ['NORM']\n",
      "1207 ['STTC']\n",
      "1208 ['NORM']\n",
      "1209 ['NORM']\n",
      "1210 ['MI']\n",
      "1211 ['CD', 'MI']\n",
      "1212 ['NORM']\n",
      "1213 ['CD']\n",
      "1214 ['STTC', 'HYP']\n",
      "1215 ['STTC', 'CD']\n",
      "1216 ['CD']\n",
      "1217 ['NORM']\n",
      "1218 ['NORM']\n",
      "1219 ['NORM']\n",
      "1220 ['STTC', 'HYP', 'CD', 'MI']\n",
      "1221 ['CD', 'MI']\n",
      "1222 ['MI']\n",
      "1223 ['NORM']\n",
      "1224 ['STTC', 'HYP']\n",
      "1225 ['NORM']\n",
      "1226 ['NORM']\n",
      "1227 ['CD', 'NORM']\n",
      "1228 ['NORM']\n",
      "1229 ['CD']\n",
      "1230 ['NORM']\n",
      "1231 ['NORM']\n",
      "1232 ['NORM']\n",
      "1233 ['NORM']\n",
      "1234 ['NORM']\n",
      "1235 ['STTC', 'CD']\n",
      "1236 ['NORM']\n",
      "1237 ['NORM']\n",
      "1238 ['NORM']\n",
      "1239 ['CD', 'MI']\n",
      "1240 ['CD', 'MI']\n",
      "1241 ['STTC', 'HYP', 'CD']\n",
      "1242 ['NORM']\n",
      "1243 ['STTC']\n",
      "1244 ['NORM']\n",
      "1245 ['STTC', 'CD']\n",
      "1246 ['STTC']\n",
      "1247 ['NORM']\n",
      "1248 ['CD', 'NORM']\n",
      "1249 ['NORM']\n",
      "1250 ['NORM']\n",
      "1251 ['MI']\n",
      "1252 ['HYP']\n",
      "1253 ['STTC', 'HYP', 'MI']\n",
      "1254 ['NORM']\n",
      "1255 ['NORM']\n",
      "1256 ['MI']\n",
      "1257 ['STTC']\n",
      "1258 ['CD', 'MI']\n",
      "1259 ['MI']\n",
      "1260 ['STTC', 'HYP']\n",
      "1261 ['NORM']\n",
      "1262 ['CD', 'MI']\n",
      "1263 ['NORM']\n",
      "1264 ['NORM']\n",
      "1265 ['STTC', 'MI']\n",
      "1266 ['NORM']\n",
      "1267 ['NORM']\n",
      "1268 ['NORM']\n",
      "1269 ['MI']\n",
      "1270 ['STTC']\n",
      "1271 ['NORM']\n",
      "1272 ['NORM']\n",
      "1273 ['MI']\n",
      "1274 ['CD']\n",
      "1275 ['NORM']\n",
      "1276 ['MI']\n",
      "1277 ['STTC', 'HYP']\n",
      "1278 ['STTC']\n",
      "1279 ['CD']\n",
      "1280 ['MI']\n",
      "1281 ['CD', 'MI']\n",
      "1282 ['STTC', 'HYP']\n",
      "1283 ['NORM']\n",
      "1284 ['MI']\n",
      "1285 ['NORM']\n",
      "1286 ['NORM']\n",
      "1287 ['CD', 'MI']\n",
      "1288 []\n",
      "1289 ['HYP']\n",
      "1290 ['NORM']\n",
      "1291 ['STTC', 'HYP', 'CD']\n",
      "1292 ['MI']\n",
      "1293 ['CD', 'MI']\n",
      "1294 ['NORM']\n",
      "1295 ['NORM']\n",
      "1296 ['NORM']\n",
      "1297 ['STTC', 'HYP']\n",
      "1298 ['NORM']\n",
      "1299 ['NORM']\n",
      "1300 ['STTC', 'MI']\n",
      "1301 ['NORM']\n",
      "1302 ['CD', 'MI']\n",
      "1303 ['NORM']\n",
      "1304 ['NORM']\n",
      "1305 ['NORM']\n",
      "1306 ['CD']\n",
      "1307 ['NORM']\n",
      "1308 ['STTC']\n",
      "1309 ['MI']\n",
      "1310 ['NORM']\n",
      "1311 ['MI']\n",
      "1312 ['STTC', 'MI']\n",
      "1313 ['STTC', 'CD', 'MI']\n",
      "1314 ['STTC', 'CD']\n",
      "1315 ['STTC', 'HYP']\n",
      "1316 ['MI']\n",
      "1317 ['CD']\n",
      "1318 ['NORM']\n",
      "1319 ['NORM']\n",
      "1320 ['CD']\n",
      "1321 ['CD']\n",
      "1322 ['NORM']\n",
      "1323 ['CD', 'MI']\n",
      "1324 ['NORM']\n",
      "1325 ['STTC']\n",
      "1326 ['NORM']\n",
      "1327 ['MI']\n",
      "1328 ['NORM']\n",
      "1329 ['NORM']\n",
      "1330 ['CD', 'NORM']\n",
      "1331 ['NORM']\n",
      "1332 ['NORM']\n",
      "1333 ['STTC']\n",
      "1334 ['NORM']\n",
      "1335 ['STTC']\n",
      "1336 ['STTC']\n",
      "1337 ['STTC', 'HYP']\n",
      "1338 ['STTC']\n",
      "1339 ['NORM']\n",
      "1340 ['CD']\n",
      "1341 ['NORM']\n",
      "1342 ['STTC', 'HYP', 'MI']\n",
      "1343 ['CD', 'MI']\n",
      "1344 ['NORM']\n",
      "1345 []\n",
      "1346 ['STTC']\n",
      "1347 ['STTC', 'HYP']\n",
      "1348 ['STTC']\n",
      "1349 ['MI']\n",
      "1350 ['STTC', 'HYP', 'MI']\n",
      "1351 ['STTC']\n",
      "1352 ['NORM']\n",
      "1353 ['CD']\n",
      "1354 ['NORM']\n",
      "1355 ['NORM']\n",
      "1356 ['MI']\n",
      "1357 ['STTC']\n",
      "1358 ['NORM']\n",
      "1359 ['NORM']\n",
      "1360 ['MI']\n",
      "1361 ['NORM']\n",
      "1362 ['NORM']\n",
      "1363 ['NORM']\n",
      "1364 ['STTC', 'MI']\n",
      "1365 ['NORM']\n",
      "1366 ['HYP']\n",
      "1367 ['CD']\n",
      "1368 ['STTC', 'HYP', 'MI']\n",
      "1369 ['CD']\n",
      "1370 ['STTC']\n",
      "1371 ['STTC']\n",
      "1372 ['CD', 'MI']\n",
      "1373 ['NORM']\n",
      "1374 ['STTC']\n",
      "1375 ['NORM']\n",
      "1376 ['NORM']\n",
      "1377 ['MI']\n",
      "1378 ['CD', 'MI']\n",
      "1379 ['HYP']\n",
      "1380 ['NORM']\n",
      "1381 ['CD', 'NORM']\n",
      "1382 ['STTC', 'HYP']\n",
      "1383 ['MI']\n",
      "1384 ['NORM']\n",
      "1385 ['STTC', 'CD']\n",
      "1386 ['NORM']\n",
      "1387 ['STTC', 'CD', 'MI']\n",
      "1388 ['NORM']\n",
      "1389 ['NORM']\n",
      "1390 ['CD', 'MI']\n",
      "1391 ['MI']\n",
      "1392 ['CD', 'MI']\n",
      "1393 ['NORM']\n",
      "1394 ['NORM']\n",
      "1395 ['NORM']\n",
      "1396 ['STTC']\n",
      "1397 ['CD']\n",
      "1398 ['CD']\n",
      "1399 ['NORM']\n",
      "1400 ['STTC']\n",
      "1401 ['NORM']\n",
      "1402 ['MI']\n",
      "1403 ['MI']\n",
      "1404 ['NORM']\n",
      "1405 ['STTC']\n",
      "1406 ['NORM']\n",
      "1407 ['STTC', 'CD']\n",
      "1408 ['NORM']\n",
      "1409 ['STTC', 'HYP', 'MI']\n",
      "1410 ['NORM']\n",
      "1411 ['NORM']\n",
      "1412 ['STTC']\n",
      "1413 ['CD']\n",
      "1414 ['MI']\n",
      "1415 ['CD']\n",
      "1416 ['STTC']\n",
      "1417 ['MI']\n",
      "1418 ['STTC']\n",
      "1419 ['NORM']\n",
      "1420 ['STTC', 'HYP']\n",
      "1421 ['NORM']\n",
      "1422 ['STTC', 'MI']\n",
      "1423 ['NORM']\n",
      "1424 ['NORM']\n",
      "1425 []\n",
      "1426 ['CD', 'MI']\n",
      "1427 ['CD']\n",
      "1428 ['MI']\n",
      "1429 ['STTC']\n",
      "1430 ['STTC']\n",
      "1431 ['HYP']\n",
      "1432 ['MI']\n",
      "1433 ['NORM']\n",
      "1434 ['STTC', 'NORM']\n",
      "1435 ['NORM']\n",
      "1436 ['CD', 'MI']\n",
      "1437 ['MI']\n",
      "1438 ['CD']\n",
      "1439 ['MI']\n",
      "1440 ['STTC']\n",
      "1441 ['CD', 'NORM']\n",
      "1442 ['NORM']\n",
      "1443 ['CD', 'NORM']\n",
      "1444 ['NORM']\n",
      "1445 ['HYP']\n",
      "1446 ['CD']\n",
      "1447 ['CD']\n",
      "1448 ['STTC']\n",
      "1449 ['STTC', 'HYP', 'MI']\n",
      "1450 ['NORM']\n",
      "1451 ['CD']\n",
      "1452 ['STTC', 'HYP']\n",
      "1453 ['STTC', 'HYP']\n",
      "1454 ['STTC']\n",
      "1455 ['STTC']\n",
      "1456 ['HYP']\n",
      "1457 ['NORM']\n",
      "1458 ['CD']\n",
      "1459 []\n",
      "1460 ['MI']\n",
      "1461 ['STTC', 'MI']\n",
      "1462 ['MI']\n",
      "1463 ['MI']\n",
      "1464 ['MI']\n",
      "1465 ['CD', 'MI']\n",
      "1466 ['NORM']\n",
      "1467 ['CD', 'MI']\n",
      "1468 ['NORM']\n",
      "1469 ['NORM']\n",
      "1470 ['STTC']\n",
      "1471 ['CD']\n",
      "1472 ['NORM']\n",
      "1473 ['NORM']\n",
      "1474 ['NORM']\n",
      "1475 ['NORM']\n",
      "1476 ['CD']\n",
      "1477 ['NORM']\n",
      "1478 ['NORM']\n",
      "1479 ['STTC']\n",
      "1480 ['STTC']\n",
      "1481 ['STTC', 'MI']\n",
      "1482 ['NORM']\n",
      "1483 ['CD', 'NORM']\n",
      "1484 ['STTC', 'HYP', 'CD']\n",
      "1485 ['CD']\n",
      "1486 ['HYP']\n",
      "1487 ['NORM']\n",
      "1488 ['NORM']\n",
      "1489 ['NORM']\n",
      "1490 ['MI']\n",
      "1491 ['NORM']\n",
      "1492 ['NORM']\n",
      "1493 ['MI']\n",
      "1494 ['STTC']\n",
      "1495 ['NORM']\n",
      "1496 ['STTC']\n",
      "1497 ['STTC', 'CD']\n",
      "1498 ['NORM']\n",
      "1499 ['HYP', 'MI']\n",
      "1500 ['HYP', 'MI']\n",
      "1501 ['STTC', 'CD']\n",
      "1502 ['CD']\n",
      "1503 ['CD', 'NORM']\n",
      "1504 ['NORM']\n",
      "1505 ['CD']\n",
      "1506 ['CD']\n",
      "1507 ['MI']\n",
      "1508 ['NORM']\n",
      "1509 ['NORM']\n",
      "1510 ['NORM']\n",
      "1511 ['NORM']\n",
      "1512 ['CD']\n",
      "1513 ['HYP', 'CD']\n",
      "1514 ['MI']\n",
      "1515 ['STTC']\n",
      "1516 ['NORM']\n",
      "1517 ['STTC']\n",
      "1518 ['STTC', 'HYP', 'CD']\n",
      "1519 ['NORM']\n",
      "1520 ['HYP']\n",
      "1521 ['STTC', 'MI']\n",
      "1522 ['NORM']\n",
      "1523 ['MI']\n",
      "1524 ['STTC', 'MI']\n",
      "1525 ['NORM']\n",
      "1526 ['NORM']\n",
      "1527 ['CD']\n",
      "1528 ['NORM']\n",
      "1529 ['NORM']\n",
      "1530 ['STTC', 'CD']\n",
      "1531 ['STTC', 'HYP']\n",
      "1532 ['NORM']\n",
      "1533 ['NORM']\n",
      "1534 ['NORM']\n",
      "1535 ['CD']\n",
      "1536 ['NORM']\n",
      "1537 ['STTC', 'HYP']\n",
      "1538 ['CD']\n",
      "1539 ['STTC', 'NORM']\n",
      "1540 ['CD', 'MI']\n",
      "1541 ['STTC']\n",
      "1542 ['CD', 'NORM']\n",
      "1543 ['STTC', 'MI']\n",
      "1544 ['NORM']\n",
      "1545 ['NORM']\n",
      "1546 ['STTC']\n",
      "1547 ['STTC']\n",
      "1548 ['NORM']\n",
      "1549 ['MI']\n",
      "1550 ['MI']\n",
      "1551 ['NORM']\n",
      "1552 ['STTC', 'CD', 'MI']\n",
      "1553 ['CD']\n",
      "1554 ['NORM']\n",
      "1555 ['NORM']\n",
      "1556 ['CD']\n",
      "1557 ['NORM']\n",
      "1558 ['NORM']\n",
      "1559 ['NORM']\n",
      "1560 ['CD']\n",
      "1561 ['NORM']\n",
      "1562 ['STTC', 'HYP']\n",
      "1563 ['CD', 'MI']\n",
      "1564 ['STTC', 'HYP', 'MI']\n",
      "1565 ['MI']\n",
      "1566 ['STTC', 'CD', 'MI']\n",
      "1567 ['STTC', 'MI']\n",
      "1568 ['MI']\n",
      "1569 ['CD', 'MI']\n",
      "1570 ['NORM']\n",
      "1571 ['STTC']\n",
      "1572 ['NORM']\n",
      "1573 ['NORM']\n",
      "1574 ['NORM']\n",
      "1575 ['CD']\n",
      "1576 ['CD']\n",
      "1577 ['CD']\n",
      "1578 ['CD']\n",
      "1579 ['NORM']\n",
      "1580 ['MI']\n",
      "1581 ['NORM']\n",
      "1582 ['MI']\n",
      "1583 ['MI']\n",
      "1584 ['MI']\n",
      "1585 ['CD', 'MI']\n",
      "1586 ['NORM']\n",
      "1587 ['CD']\n",
      "1588 ['STTC', 'MI']\n",
      "1589 ['CD']\n",
      "1590 ['CD']\n",
      "1591 ['STTC', 'CD']\n",
      "1592 ['MI']\n",
      "1593 ['STTC']\n",
      "1594 ['NORM']\n",
      "1595 ['STTC']\n",
      "1596 ['NORM']\n",
      "1597 ['STTC']\n",
      "1598 ['STTC']\n",
      "1599 ['NORM']\n",
      "1600 ['NORM']\n",
      "1601 ['STTC']\n",
      "1602 ['NORM']\n",
      "1603 ['NORM']\n",
      "1604 ['NORM']\n",
      "1605 ['NORM']\n",
      "1606 ['CD']\n",
      "1607 ['NORM']\n",
      "1608 ['MI']\n",
      "1609 ['NORM']\n",
      "1610 ['STTC']\n",
      "1611 ['CD']\n",
      "1612 ['MI']\n",
      "1613 ['NORM']\n",
      "1614 ['MI']\n",
      "1615 ['MI']\n",
      "1616 ['STTC', 'MI']\n",
      "1617 ['MI']\n",
      "1618 ['MI']\n",
      "1619 ['STTC', 'CD']\n",
      "1620 ['NORM']\n",
      "1621 ['NORM']\n",
      "1622 ['STTC']\n",
      "1623 ['NORM']\n",
      "1624 ['CD', 'NORM']\n",
      "1625 ['NORM']\n",
      "1626 ['STTC']\n",
      "1627 ['STTC', 'HYP', 'MI']\n",
      "1628 ['STTC']\n",
      "1629 ['MI']\n",
      "1630 ['MI']\n",
      "1631 ['MI']\n",
      "1632 ['NORM']\n",
      "1633 ['HYP', 'CD', 'MI']\n",
      "1634 ['CD']\n",
      "1635 ['NORM']\n",
      "1636 ['CD', 'MI']\n",
      "1637 ['CD', 'MI']\n",
      "1638 ['CD', 'MI']\n",
      "1639 ['NORM']\n",
      "1640 ['CD']\n",
      "1641 ['NORM']\n",
      "1642 ['MI']\n",
      "1643 ['CD']\n",
      "1644 ['NORM']\n",
      "1645 ['NORM']\n",
      "1646 ['CD', 'MI']\n",
      "1647 ['CD']\n",
      "1648 ['NORM']\n",
      "1649 ['NORM']\n",
      "1650 ['STTC', 'CD', 'MI']\n",
      "1651 ['NORM']\n",
      "1652 ['NORM']\n",
      "1653 ['MI']\n",
      "1654 ['NORM']\n",
      "1655 ['NORM']\n",
      "1656 ['NORM']\n",
      "1657 ['STTC']\n",
      "1658 ['NORM']\n",
      "1659 ['STTC']\n",
      "1660 ['NORM']\n",
      "1661 ['STTC']\n",
      "1662 ['MI']\n",
      "1663 ['STTC']\n",
      "1664 []\n",
      "1665 ['CD']\n",
      "1666 ['NORM']\n",
      "1667 ['CD']\n",
      "1668 ['NORM']\n",
      "1669 ['CD']\n",
      "1670 ['STTC']\n",
      "1671 ['NORM']\n",
      "1672 ['HYP']\n",
      "1673 ['STTC', 'HYP', 'CD', 'MI']\n",
      "1674 ['NORM']\n",
      "1675 ['CD', 'MI']\n",
      "1676 ['STTC', 'HYP']\n",
      "1677 ['STTC', 'MI']\n",
      "1678 ['NORM']\n",
      "1679 ['HYP']\n",
      "1680 ['CD']\n",
      "1681 ['NORM']\n",
      "1682 ['MI']\n",
      "1683 ['CD', 'MI']\n",
      "1684 ['CD', 'MI']\n",
      "1685 ['MI']\n",
      "1686 ['MI']\n",
      "1687 ['NORM']\n",
      "1688 ['HYP']\n",
      "1689 ['NORM']\n",
      "1690 ['NORM']\n",
      "1691 []\n",
      "1692 ['CD', 'MI']\n",
      "1693 ['NORM']\n",
      "1694 ['NORM']\n",
      "1695 ['STTC']\n",
      "1696 ['STTC']\n",
      "1697 ['NORM']\n",
      "1698 ['NORM']\n",
      "1699 ['NORM']\n",
      "1700 ['CD', 'MI']\n",
      "1701 ['NORM']\n",
      "1702 ['CD']\n",
      "1703 ['STTC']\n",
      "1704 ['MI']\n",
      "1705 ['STTC']\n",
      "1706 ['NORM']\n",
      "1707 ['CD', 'MI']\n",
      "1708 ['STTC']\n",
      "1709 ['NORM']\n",
      "1710 ['NORM']\n",
      "1711 ['CD']\n",
      "1712 ['NORM']\n",
      "1713 ['STTC']\n",
      "1714 ['NORM']\n",
      "1715 ['HYP', 'CD']\n",
      "1716 ['MI']\n",
      "1717 ['MI']\n",
      "1718 ['CD']\n",
      "1719 ['STTC']\n",
      "1720 ['STTC', 'HYP']\n",
      "1721 ['MI']\n",
      "1722 ['NORM']\n",
      "1723 ['STTC']\n",
      "1724 ['STTC', 'HYP', 'MI']\n",
      "1725 ['CD']\n",
      "1726 ['CD', 'MI']\n",
      "1727 ['STTC', 'HYP', 'MI']\n",
      "1728 ['NORM']\n",
      "1729 ['CD']\n",
      "1730 ['NORM']\n",
      "1731 ['NORM']\n",
      "1732 ['STTC', 'HYP', 'CD']\n",
      "1733 ['NORM']\n",
      "1734 ['STTC', 'HYP']\n",
      "1735 ['MI']\n",
      "1736 ['NORM']\n",
      "1737 ['STTC', 'HYP']\n",
      "1738 ['STTC', 'HYP', 'CD']\n",
      "1739 ['CD', 'MI']\n",
      "1740 ['CD', 'MI']\n",
      "1741 ['NORM']\n",
      "1742 ['CD']\n",
      "1743 ['NORM']\n",
      "1744 ['CD']\n",
      "1745 ['MI']\n"
     ]
    }
   ],
   "source": [
    "X_train = X[np.where(Y.strat_fold != test_fold)]\n",
    "y_train = Y[(Y.strat_fold != test_fold)].diagnostic_superclass\n",
    "# Test\n",
    "X_test = X[np.where(Y.strat_fold == test_fold)]\n",
    "y_test = Y[Y.strat_fold == test_fold].diagnostic_superclass\n",
    "\n",
    "del X\n",
    "del Y\n",
    "\n",
    "flattened_y_train = [item for sublist in y_train for item in sublist]\n",
    "flattened_y_test = [item for sublist in y_test for item in sublist]\n",
    "\n",
    "# Get all unique categories from flattened lists\n",
    "all_categories = sorted(set(flattened_y_train + flattened_y_test))\n",
    "\n",
    "\n",
    "# One-hot encode y_train\n",
    "y_train_encoded = pd.DataFrame(0, index=range(len(y_train)), columns=all_categories)\n",
    "for i, categories in enumerate(y_train):\n",
    "    y_train_encoded.loc[i, categories] = 1\n",
    "\n",
    "# One-hot encode y_test\n",
    "y_test_encoded = pd.DataFrame(0, index=range(len(y_test)), columns=all_categories)\n",
    "for i, categories in enumerate(y_test):\n",
    "    y_test_encoded.loc[i, categories] = 1\n",
    "    print(i, categories)\n",
    "\n",
    "# Convert to list of lists\n",
    "y_train_encoded = y_train_encoded.values.tolist()\n",
    "y_test_encoded = y_test_encoded.values.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29b52912-bb9a-49b0-8088-5dfe767a2882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Usage: 4939.67 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get the current process ID (PID)\n",
    "pid = psutil.Process()\n",
    "\n",
    "# Get the memory information\n",
    "memory_info = pid.memory_info()\n",
    "\n",
    "# RAM usage in bytes\n",
    "ram_usage_bytes = memory_info.rss\n",
    "\n",
    "# Convert bytes to megabytes (MB) for a more readable output\n",
    "ram_usage_mb = ram_usage_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"RAM Usage: {ram_usage_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee75f6ff-759f-40a0-a13b-9a0ed3514cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212544\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for t in range(len(X_train)):\n",
    "    for i in range(12):\n",
    "        counter+=1\n",
    "        denoiser = WaveletDenoiserWithThresholdPerLevel(wavelet='db4', level=4)\n",
    "        X_train[t,:,i] = denoiser.process(X_train[t,:, i])\n",
    "for t in range(len(X_test)):\n",
    "    for i in range(12):\n",
    "        counter+=1\n",
    "        denoiser = WaveletDenoiserWithThresholdPerLevel(wavelet='db4', level=4)\n",
    "        X_test[t,:,i] = denoiser.process(X_test[t,:, i])\n",
    "print(counter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73df2b3a-2d5b-4dc2-ac07-1acd6ae4c65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15966, 5000, 12)\n",
      "(1746, 5000, 12)\n",
      "(14592, 5000, 12)\n",
      "(1603, 5000, 12)\n",
      "(14592, 5)\n",
      "(1603, 5)\n"
     ]
    }
   ],
   "source": [
    "print((X_train).shape)\n",
    "print((X_test).shape)\n",
    "#print(len(y_train_encoded))\n",
    "#print(len(y_test_encoded))\n",
    "\n",
    "mask1 = (np.abs(X_train) > 3.0).any(axis=-1).any(axis=1)\n",
    "mask2 = (np.abs(X_test) > 3.0).any(axis=-1).any(axis=1)\n",
    "\n",
    "X_train = X_train[~mask1]\n",
    "X_test = X_test[~mask2]\n",
    "\n",
    "y_train_encoded=np.delete(y_train_encoded, np.where(mask1), axis=0)\n",
    "y_test_encoded=np.delete(y_test_encoded, np.where(mask2), axis=0)\n",
    "print((X_train).shape)\n",
    "print((X_test).shape)\n",
    "print((y_train_encoded).shape)\n",
    "print((y_test_encoded).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7526030-669b-44f9-8ac9-15c289c2b17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3346\n",
      "1732\n",
      "3788\n",
      "7342\n",
      "3579\n",
      "365\n",
      "194\n",
      "411\n",
      "791\n",
      "392\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(y_train_encoded[:, 0] == 1))\n",
    "print(np.count_nonzero(y_train_encoded[:, 1] == 1))\n",
    "print(np.count_nonzero(y_train_encoded[:, 2] == 1))\n",
    "print(np.count_nonzero(y_train_encoded[:, 3] == 1))\n",
    "print(np.count_nonzero(y_train_encoded[:, 4] == 1))\n",
    "\n",
    "print(np.count_nonzero(y_test_encoded[:, 0] == 1))\n",
    "print(np.count_nonzero(y_test_encoded[:, 1] == 1))\n",
    "print(np.count_nonzero(y_test_encoded[:, 2] == 1))\n",
    "print(np.count_nonzero(y_test_encoded[:, 3] == 1))\n",
    "print(np.count_nonzero(y_test_encoded[:, 4] == 1))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train_encoded.shape)\n",
    "print(y_test_encoded.shape)\n",
    "\n",
    "#3898 365+3346     CD\n",
    "#2124   1732+194   HYP\n",
    "#4302   411+3788   MI\n",
    "#8174 7342+791   NORM \n",
    "#4144   3579+392   STTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac93760-42ec-4efe-b1a1-566f011cfcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[:,500:4500,:]\n",
    "\n",
    "X_train = np.split(X_train, 4, axis=1)\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "\n",
    "X_test=X_test[:,500:4500,:]\n",
    "\n",
    "X_test = np.split(X_test, 4, axis=1)\n",
    "\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "\n",
    "print((X_train).shape)\n",
    "print((X_test).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c5323b1-fac1-4149-ba36-9fd621c565bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=torch.tensor(y_train_encoded)#.repeat(4,1)\n",
    "#= torch.tensor(y_train_encoded).repeat(4,1)\n",
    "\n",
    "y_test=torch.tensor(y_test_encoded)#.repeat(4,1)\n",
    "#= torch.tensor(y_test_encoded).repeat(4,1)\n",
    "del y_train_encoded\n",
    "del y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49737696-b826-4888-941d-3867cbbea25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3008\n",
      "1266\n",
      "3526\n",
      "7132\n",
      "3191\n",
      "325\n",
      "156\n",
      "382\n",
      "769\n",
      "351\n",
      "1266\n",
      "156\n",
      "7132\n",
      "769\n",
      "torch.Size([14592])\n",
      "torch.Size([1603])\n",
      "tensor([1, 1, 1,  ..., 1, 0, 1])\n",
      "tensor([1, 1, 1,  ..., 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(y_train[:, 0] == 1))\n",
    "print(np.count_nonzero(y_train[:, 1] == 1))\n",
    "print(np.count_nonzero(y_train[:, 2] == 1))\n",
    "print(np.count_nonzero(y_train[:, 3] == 1))\n",
    "print(np.count_nonzero(y_train[:, 4] == 1))\n",
    "\n",
    "print(np.count_nonzero(y_test[:, 0] == 1))\n",
    "print(np.count_nonzero(y_test[:, 1] == 1))\n",
    "print(np.count_nonzero(y_test[:, 2] == 1))\n",
    "print(np.count_nonzero(y_test[:, 3] == 1))\n",
    "print(np.count_nonzero(y_test[:, 4] == 1))\n",
    "\n",
    "cnt=0\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i,1]==1:\n",
    "        cnt+=1\n",
    "print(cnt)\n",
    "cnt=0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i,1]==1:\n",
    "        cnt+=1\n",
    "print(cnt)\n",
    "\n",
    "y_train = y_train[:,3]\n",
    "\n",
    "\n",
    "y_test = y_test[:,3]\n",
    "\n",
    "cnt=0\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]==1:\n",
    "        cnt+=1\n",
    "print(cnt)\n",
    "cnt=0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i]==1:\n",
    "        cnt+=1\n",
    "print(cnt)\n",
    "\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d14c0bd-4c16-4ee9-ab22-4ae019e3a031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "y_train=torch.tensor(y_train)\n",
    "y_test=torch.tensor(y_test)\n",
    "print(type(y_train))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25b73dcf-b42b-46f1-9a50-cc3366854736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14592, 5000, 12])\n",
      "torch.Size([0, 5000, 12])\n",
      "torch.Size([1603, 5000, 12])\n",
      "torch.Size([14592])\n",
      "torch.Size([0])\n",
      "torch.Size([1603])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20550/1752898658.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_valid=torch.tensor(y_train[15000:]) #ok\n",
      "/tmp/ipykernel_20550/1752898658.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train=torch.tensor(y_train[:15000]) # ok\n",
      "/tmp/ipykernel_20550/1752898658.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test=torch.tensor(y_test) #ok\n"
     ]
    }
   ],
   "source": [
    "class FlattenScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, scaler):\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X.reshape(-1, 1))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return self.scaler.transform(X.reshape(-1, 1)).reshape(X.shape)\n",
    "\n",
    "#sc = FlattenScaler(MinMaxScaler())\n",
    "#X_train = sc.fit_transform(X_train)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "\n",
    "X_test= torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "X_valid=X_train[15000:,:,:] #ok\n",
    "X_train=X_train[:15000,:,:] # ok\n",
    "\n",
    "\n",
    "y_valid=torch.tensor(y_train[15000:]) #ok\n",
    "y_train=torch.tensor(y_train[:15000]) # ok\n",
    "y_test=torch.tensor(y_test) #ok\n",
    "# X_test , y_test_encoded\n",
    "print((X_train).shape)\n",
    "print((X_valid).shape)\n",
    "print((X_test).shape)\n",
    "print((y_train).shape)\n",
    "print((y_valid).shape)\n",
    "print((y_test).shape)\n",
    "\n",
    "#X_train=torch.tensor(X_train,dtype=torch.float32)\n",
    "#y_train=torch.tensor(np.array(y_train_encoded),dtype=torch.float32)\n",
    "#print(y_train_encoded)\n",
    "#print(X_train.shape)\n",
    "#print(y_train.shape)\n",
    "#print(type(X_test))\n",
    "#print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fc0e1b6-2536-4d5e-a102-25a033333260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15000, 5000, 12])\n",
      "torch.Size([0, 5000, 12])\n",
      "torch.Size([1708, 5000, 12])\n",
      "torch.Size([15000])\n",
      "torch.Size([615])\n",
      "torch.Size([1708])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(y_valid))\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(y_test))\n\u001b[0;32m---> 15\u001b[0m y_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(y_train)\n\u001b[1;32m     16\u001b[0m y_valid \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(y_valid)\n\u001b[1;32m     17\u001b[0m y_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(y_test)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "print((X_train).shape)\n",
    "print((X_valid).shape)\n",
    "print((X_test).shape)\n",
    "print((y_train).shape)\n",
    "print((y_valid).shape)\n",
    "print((y_test).shape)\n",
    "\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(X_valid))\n",
    "print(type(X_test))\n",
    "print(type(y_train))\n",
    "print(type(y_valid))\n",
    "print(type(y_test))\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_valid = torch.from_numpy(y_valid)\n",
    "y_test = torch.from_numpy(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9601c262-7eaa-4757-836b-4cfefe5f9197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([79971, 1000, 12])\n",
      "torch.Size([79971, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "indices = torch.nonzero(y_train == 1, as_tuple=False)[:, 0]\n",
    "selected_tensors = X_train[indices]\n",
    "num_selected_samples = selected_tensors.size(0)\n",
    "# Concatenate the selected tensors at the end of X\n",
    "X_train = torch.cat((X_train, selected_tensors, selected_tensors,selected_tensors), dim=0)\n",
    "\n",
    "ones_to_add = torch.ones(size=(num_selected_samples*3,1), dtype=torch.int16)\n",
    "y_train = torch.cat((y_train, ones_to_add), dim=0)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44488783-4830-4233-bd03-7a8024526a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "        elif val_loss > self.best_score - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "    \"\"\"def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\"\"\"\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94f439d8-e758-441b-a267-8c27a8fd9902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Usage: 3763.89 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get the current process ID (PID)\n",
    "pid = psutil.Process()\n",
    "\n",
    "# Get the memory information\n",
    "memory_info = pid.memory_info()\n",
    "\n",
    "# RAM usage in bytes\n",
    "ram_usage_bytes = memory_info.rss\n",
    "\n",
    "# Convert bytes to megabytes (MB) for a more readable output\n",
    "ram_usage_mb = ram_usage_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"RAM Usage: {ram_usage_mb:.2f} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dbfd962-4b4c-49ae-86d9-f5e88c6631db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_channels=12, num_classes=1, kernel_size=5):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "         # First Conv1D layer\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size, padding=2)\n",
    "        \n",
    "        # Second Conv1D layer\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size, padding=2)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size, padding=2)\n",
    "        \n",
    "        self.linear = nn.Linear(128*625, 32)\n",
    "        self.output = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the layers\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "        \n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "        \n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "\n",
    "        # Flatten the output before the linear layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = nn.functional.relu(self.linear(x))\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4b165a9-bbd5-47df-aa01-ad3331801aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7496, 1.5016])\n"
     ]
    }
   ],
   "source": [
    "#y_train = torch.tensor(y_train).squeeze()\n",
    "\n",
    "class_weight = torch.tensor(sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=[0, 1], y=np.array(y_train).flatten()), dtype=torch.float32)\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32a9eca3-c60c-4697-a18d-ef21bd48fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([14592, 5000, 12])\n",
      "torch.Size([0, 5000, 12])\n",
      "torch.Size([14592])\n",
      "torch.Size([0])\n",
      "7132\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_valid))\n",
    "print(type(y_train))\n",
    "print(type(y_valid))\n",
    "print((X_train).shape)\n",
    "print((X_valid).shape)\n",
    "print((y_train).shape)\n",
    "print((y_valid).shape)\n",
    "cnt=0\n",
    "for i in y_train:\n",
    "    if i==1:\n",
    "        cnt=cnt+1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee9fc624-7ad3-4a0a-8e56-f5643a4b8a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([73314, 1000, 12])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NoisyECGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        signal = self.data[index]\n",
    "        noisy_signal = self.add_random_noise(signal)\n",
    "        return noisy_signal\n",
    "\n",
    "    def add_random_noise(self, signal):\n",
    "        signal = signal.numpy()\n",
    "        \n",
    "        magnitude_warp = np.random.normal(1, 0.1, signal.shape)\n",
    "        signal = signal + magnitude_warp*signal# magnitude warp\n",
    "\n",
    "        scale = np.random.normal(1, 0.05)\n",
    "        signal = scale*signal  # rescale\n",
    "\n",
    "        noise = np.random.normal(0, 0.01, signal.shape)\n",
    "        signal = noise + signal  # static noise\n",
    "\n",
    "        return torch.from_numpy(signal)\n",
    "\n",
    "#print(X_train.shape)\n",
    "train_dataset = NoisyECGDataset(X_train).data\n",
    "plt.plot(train_dataset[0,:,0])\n",
    "X_train=train_dataset\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d06e6ac-4889-4cb8-ab72-5ca3370ce5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 3648/3648 [02:14<00:00, 27.19batch/s, Training Loss=0.1642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2545\n",
      "6987\n",
      "1 Loss: 0.1642 Acc: 0.6532\n",
      "Epoch 1 Validation Loss: 0.1611 Validation Acc: 0.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 3648/3648 [02:15<00:00, 26.93batch/s, Training Loss=0.1583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573\n",
      "6687\n",
      "2 Loss: 0.1583 Acc: 0.7717\n",
      "Epoch 2 Validation Loss: 0.1555 Validation Acc: 0.7498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 3648/3648 [02:17<00:00, 26.61batch/s, Training Loss=0.1496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5354\n",
      "6449\n",
      "3 Loss: 0.1496 Acc: 0.8089\n",
      "Epoch 3 Validation Loss: 0.1541 Validation Acc: 0.7611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 3648/3648 [02:12<00:00, 27.54batch/s, Training Loss=0.1482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5428\n",
      "6496\n",
      "4 Loss: 0.1482 Acc: 0.8172\n",
      "Epoch 4 Validation Loss: 0.1570 Validation Acc: 0.7867\n",
      "EarlyStopping counter: 1 out of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 3648/3648 [02:14<00:00, 27.22batch/s, Training Loss=0.1471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5531\n",
      "6545\n",
      "5 Loss: 0.1471 Acc: 0.8276\n",
      "Epoch 5 Validation Loss: 0.1531 Validation Acc: 0.7929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 3648/3648 [02:12<00:00, 27.49batch/s, Training Loss=0.1466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5629\n",
      "6543\n",
      "6 Loss: 0.1466 Acc: 0.8342\n",
      "Epoch 6 Validation Loss: 0.1542 Validation Acc: 0.7916\n",
      "EarlyStopping counter: 1 out of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 3648/3648 [02:12<00:00, 27.53batch/s, Training Loss=0.1461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5612\n",
      "6589\n",
      "7 Loss: 0.1461 Acc: 0.8361\n",
      "Epoch 7 Validation Loss: 0.1537 Validation Acc: 0.7898\n",
      "EarlyStopping counter: 2 out of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 3648/3648 [02:07<00:00, 28.69batch/s, Training Loss=0.1455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5689\n",
      "6604\n",
      "8 Loss: 0.1455 Acc: 0.8424\n",
      "Epoch 8 Validation Loss: 0.1540 Validation Acc: 0.7898\n",
      "EarlyStopping counter: 3 out of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 3648/3648 [02:17<00:00, 26.52batch/s, Training Loss=0.1450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5726\n",
      "6627\n",
      "9 Loss: 0.1450 Acc: 0.8466\n",
      "Epoch 9 Validation Loss: 0.1529 Validation Acc: 0.7754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 3648/3648 [02:16<00:00, 26.65batch/s, Training Loss=0.1449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5702\n",
      "6641\n",
      "10 Loss: 0.1449 Acc: 0.8459\n",
      "Epoch 10 Validation Loss: 0.1532 Validation Acc: 0.7923\n",
      "EarlyStopping counter: 1 out of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 3648/3648 [02:18<00:00, 26.35batch/s, Training Loss=0.1441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5785\n",
      "6669\n",
      "11 Loss: 0.1441 Acc: 0.8535\n",
      "Epoch 11 Validation Loss: 0.1536 Validation Acc: 0.7642\n",
      "EarlyStopping counter: 2 out of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 3648/3648 [02:15<00:00, 26.88batch/s, Training Loss=0.1438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5810\n",
      "6703\n",
      "12 Loss: 0.1438 Acc: 0.8575\n",
      "Epoch 12 Validation Loss: 0.1547 Validation Acc: 0.7941\n",
      "EarlyStopping counter: 3 out of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 3648/3648 [02:15<00:00, 26.92batch/s, Training Loss=0.1434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5885\n",
      "6687\n",
      "13 Loss: 0.1434 Acc: 0.8616\n",
      "Epoch 13 Validation Loss: 0.1532 Validation Acc: 0.7954\n",
      "EarlyStopping counter: 4 out of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30:  45%|████▍     | 1627/3648 [01:00<01:15, 26.74batch/s, Training Loss=0.1429]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m     72\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 73\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     74\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     75\u001b[0m total_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(labels)\n",
      "File \u001b[0;32m~/anaconda3/envs/psiml/lib/python3.11/site-packages/torch/optim/optimizer.py:269\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m args\n\u001b[1;32m    268\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m--> 269\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m    270\u001b[0m     \u001b[39m# call optimizer step pre hooks\u001b[39;00m\n\u001b[1;32m    271\u001b[0m     \u001b[39mfor\u001b[39;00m pre_hook \u001b[39min\u001b[39;00m chain(_global_optimizer_pre_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_pre_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    272\u001b[0m         result \u001b[39m=\u001b[39m pre_hook(\u001b[39mself\u001b[39m, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/psiml/lib/python3.11/site-packages/torch/autograd/profiler.py:492\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 492\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39m_record_function_enter_new(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs)\n\u001b[1;32m    493\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/psiml/lib/python3.11/site-packages/torch/_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    498\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs \u001b[39mor\u001b[39;00m {})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Calculate mean and standard deviation of your training data\n",
    "#mean = X_train.mean()\n",
    "#std = X_train.std()\n",
    "\n",
    "## Define a normalization transform\n",
    "#transform = transforms.Compose([\n",
    "#    transforms.ToTensor(),  # Convert data to tensor (if not already)\n",
    "#    transforms.Normalize(mean, std)  # Normalize the data\n",
    "#])\n",
    "\n",
    "## Apply the normalization transform to your training and test data\n",
    "#normalized_X_train = transform(X_train)\n",
    "#normalized_X_test = transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device=torch.device('cpu')\n",
    "# Initialize the model         #10000 15000 512\n",
    "epochs=30\n",
    "num_classes = 1\n",
    "learn_rate=0.00005\n",
    "model=SimpleCNN()\n",
    "batch=4\n",
    "# Define loss function and optimizer\n",
    "#class_weight[1] *= 2.0\n",
    "#criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(class_weight[1]).clone().detach())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
    "#X_train_tensor_normalized=sc.transform(X_train_tensor)\n",
    "# Create DataLoader for training and testing\n",
    "print(\"1\")\n",
    "train_dataset = TensorDataset(X_train.permute(0,2,1), y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "total_train_batches = len(train_loader)\n",
    "valid_dataset = TensorDataset(X_test.permute(0,2,1), y_test)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch)\n",
    "\n",
    "\n",
    "best_validation_loss = float('inf')\n",
    "train_loss_values = []\n",
    "train_accuracy_values = []\n",
    "average_validation_loss=0.0\n",
    "average_train_loss=0.0\n",
    "valid_loss_values=[]\n",
    "valid_accuracy_values=[]\n",
    "metrics=[]\n",
    "plt.ion()\n",
    "total_loss=0.0\n",
    "early_stopping = EarlyStopping(patience=6, verbose=True)\n",
    "# training and testing\n",
    "pom=0\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    correct_predictions_for_1=0\n",
    "    correct_predictions_for_0=0\n",
    "    total_samples = 0\n",
    "    with tqdm(total=total_train_batches, desc=f'Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            #print(outputs)\n",
    "            #print(labels)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total_samples += len(labels)\n",
    "            pred = outputs>0.5\n",
    "            correct_predictions += (pred == labels).all(dim=1).sum().item()\n",
    "            correct_predictions_for_1 += np.sum((pred.numpy() == 1) & (labels.numpy() == 1))\n",
    "            correct_predictions_for_0 += np.sum((pred.numpy() == 0) & (labels.numpy() == 0))\n",
    "            # Update the progress bar\n",
    "            pbar.set_postfix({'Training Loss': f'{total_loss / total_samples:.4f}'})\n",
    "            pbar.update(1)\n",
    "    print(correct_predictions_for_1)\n",
    "    print(correct_predictions_for_0)\n",
    "    average_train_loss = total_loss / total_samples\n",
    "    epoch_loss = total_loss / total_samples\n",
    "    epoch_acc = float(correct_predictions) / total_samples\n",
    "    train_loss_values.append(epoch_loss)\n",
    "    train_accuracy_values.append(epoch_acc)\n",
    "    print(f'{epoch + 1} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():  # Disable gradient computation during validation\n",
    "        for inputs, labels in valid_loader:\n",
    "            outputs = model(inputs) \n",
    "            loss = criterion(outputs, labels.float())\n",
    "            total_loss += loss.item()\n",
    "            total_samples += len(labels)\n",
    "            pred = (outputs > 0.5)\n",
    "            correct_predictions += (pred == labels).all(dim=1).sum().item()\n",
    "    average_validation_loss = total_loss / total_samples\n",
    "    epoch_loss = total_loss/ total_samples\n",
    "    epoch_acc = float(correct_predictions) / total_samples\n",
    "    valid_loss_values.append(epoch_loss)\n",
    "    valid_accuracy_values.append(epoch_acc)\n",
    "    print(f'Epoch {epoch + 1} Validation Loss: {epoch_loss:.4f} Validation Acc: {epoch_acc:.4f}')\n",
    "    early_stopping(average_validation_loss, model)\n",
    "    if average_validation_loss < best_validation_loss:\n",
    "        best_validation_loss = average_validation_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping: Validation loss did not improve in the last\", early_stopping.patience, \"epochs.\")\n",
    "        break\n",
    "\n",
    "plt.ioff()\n",
    "plt.figure()\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_loss_values, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training Accuracy\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(train_accuracy_values, label='Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Validation Loss and Validation Accuracy\n",
    "plt.figure()\n",
    "plt.plot(valid_loss_values, label='Validation Loss')\n",
    "plt.plot(valid_accuracy_values, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fe0d814-39e1-4eae-b789-930714e7dcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15000, 5000, 12])\n",
      "torch.Size([15000, 1])\n",
      "torch.Size([1708, 5000, 12])\n",
      "torch.Size([1708, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b67535b-5bf5-48f6-acde-7db307e16f99",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m         total_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(labels)\n\u001b[1;32m     20\u001b[0m \u001b[39m# Calculate Test Accuracy\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m test_accuracy \u001b[39m=\u001b[39m total_correct_predictions \u001b[39m/\u001b[39m total_samples\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_accuracy\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN()  # Instantiate the model with the same architecture as during training\n",
    "model.load_state_dict(torch.load('best_model.pth')) \n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(X_valid.permute(0, 2, 1), y_valid)\n",
    "test_loader = DataLoader(test_dataset, batch_size=, shuffle=False)\n",
    "\n",
    "# Step 3: Test the Model on the Test Set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "total_correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted_labels = (outputs > 0.5).float()  # Threshold the output probabilities\n",
    "        total_correct_predictions += (predicted_labels == labels).all(dim=1).sum().item()\n",
    "        total_samples += len(labels)\n",
    "\n",
    "# Calculate Test Accuracy\n",
    "test_accuracy = total_correct_predictions / total_samples\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "753c3732",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.unsqueeze(1)\n",
    "y_test=y_test.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a6b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
